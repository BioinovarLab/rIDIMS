---
title: 'rIDIMS: An R Package For Processing Intermitent and Direct Injection Mass
  Spectrometry Data'
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
---

```{r setup, include=FALSE,echo=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE) 
set.seed(12345)
print_paged_df <- function(...) {
cat(rmarkdown:::print.paged_df(rmarkdown::paged_table(...,options = list(rows.print = 5))))
}

```

```{r,echo=FALSE}

make.replicates <- input.replicates
aggregationFun <- input.aggregationFun
percent.limit <- input.chr.limit
Tresh.RA <- input.Tresh.RA
script.error <- FALSE

cores <- c('#000000', '#FFC800', '#0077C8', '#F56A00', '#9B59B6', '#A3A3A3', '#00BFFF', '#F5D800', '#7F8C8D', '#7CFC00', '#EE82EE', '#00CED1', '#FF4500', '#DA70D6', '#FFA500', '#008080', '#1E90FF', '#8B008B', '#808000', '#FF69B4', '#8A2BE2', '#D2691E', '#FFD700', '#800080', '#008000', '#DC143C', '#4169E1', '#00FF7F', '#FF1493', '#FF00FF')

#clean output
invisible( unlink(paste0(output.folder,"*"), recursive = TRUE, force = TRUE) )

### setup
log.file <- paste0(data.folder,"log_", report.serial , ".txt")
invisible( file.remove(log.file) )
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"), ": Log started"),file=log.file,append=TRUE)
#write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"), ": Session parameters"),file=log.file,append=TRUE)
#write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"), print(session.parameters,right=F)),file=log.file,append=TRUE)
BiocParallel::register(BiocParallel::SerialParam())



```

## rIDIMS: An R Package For Processing Intermitent and Direct Injection Mass Spectrometry Data

In Mass Spectrometry (MS), the selection of scans with a good number of peaks and a high total ion current (TIC) is important for a number of reasons.

Firstly, a high number of peaks in a scan indicates that a large number of compounds are present in the sample, which increases the chances of detecting and identifying all the compounds of interest. Secondly, a high TIC indicates that a large amount of sample is being analyzed, which increases the sensitivity and accuracy of the analysis. This is particularly important when dealing with low-concentration samples or when trying to detect trace amounts of a compound. Overall, selecting scans with a good number of peaks and a high TIC ensures that the analysis is as comprehensive and accurate as possible, which is essential for reliable data interpretation and conclusions. A good number of peaks in an LC-MS scan means that the sample is highly complex and contains a large number of different compounds. This increases the chances of identifying and quantifying all the relevant compounds in the sample. On the other hand, if an LC-MS scan has a low number of peaks, it may indicate that the sample is not complex enough or that the instrument is not properly calibrated. A high TIC value indicates that the instrument is detecting a large number of ions, which can lead to more accurate quantification of the compounds in the sample. A low TIC value may indicate that the instrument is not properly calibrated or that the sample is not concentrated enough. In summary, selecting scans with a good number of peaks and a high TIC can lead to more accurate and reliable LC-MS data, which can be critical in various fields such as biochemistry, pharmacology, and environmental science.

  

```{r,echo=FALSE,warning=FALSE,message=FALSE,fig.pos='H',fig.align='center',out.width='100%',fig.height=5,fig.width=9, results='asis'}

#################
################# Process - step 1 
#################

  if (input.msresolution=="high.res"){
    message("- high resolution mode ")
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
             ': high resolution mode'),file=log.file,append=TRUE)
  }else{
    message("- low resolution mode ")
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
     ': low resolution mode'),file=log.file,append=TRUE)
  }

status.files <- data.frame()

for (file in 1:nrow(samples.info) ) {
  
  cat('\n\n## Working on:', samples.info$sample[file], '\n\n')
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
               ':## Working on: ', samples.info$sample[file]),file=log.file,append=TRUE)
  
  fine.xcms.data <- try(xcms.data <- MSnbase::readMSData(samples.info$file.dir[file], 
                                                         mode = "onDisk", #msLevel. = 1L, 
                                                         centroided. = TRUE),silent=FALSE)
  
  if ( class(fine.xcms.data) == "try-error"){
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
               ':*** Error in ', samples.info$sample[file]),file=log.file,append=TRUE)
      status.files <- rbind(status.files, c(samples.info$sample[file],
                                      "error"))
      cat('\n#### File processing error ' , '\n\n')
    next
  }
  
  if (is.null(xcms.data@featureData@data[["msLevel"]])==TRUE){
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
               ':*** Error in ', samples.info$sample[file]),file=log.file,append=TRUE)
      status.files <- rbind(status.files, c(samples.info$sample[file],
                                      "error"))
      cat('\n#### File processing error ' , '\n\n')
    next
  }
  
  
  #Shimadzu direct infusion bug correction:
  if ( sum(xcms.data@featureData@data[["msLevel"]]) == 0) {
    xcms.data@featureData@data[["msLevel"]] <- 1L
  }
  
  xcms.data <- MSnbase::filterMsLevel(xcms.data, msLevel. = 1L)
  xcms.data <- MSnbase::filterEmptySpectra(xcms.data)
  
  if (input.msresolution=="high.res"){
    #vector.input.scales <- base::strsplit(input.scales,",")[[1]]
    mfp <- xcms::MatchedFilterParam(binSize = 0.01)
    xcms::snthresh(mfp) <- input.snthresh
    ChromPeaks.data <- xcms::findChromPeaks(xcms.data, param=mfp)
  }else{
    mfp <- xcms::MatchedFilterParam(binSize = 0.01)
    xcms::snthresh(mfp) <- input.snthresh
    ChromPeaks.data <- xcms::findChromPeaks(xcms.data, param=mfp)
  }

  #make replicates and/or combine:
    if (make.replicates == "TRUE"){
      message(" making replicates ... ")
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
       ':   Make replicates'),file=log.file,append=TRUE)
      
      chrom.data <- xcms::chromatogram(ChromPeaks.data, aggregationFun = aggregationFun)
      chrom.data.item1 <- chrom.data[1, 1]
      chrom.data.item1.df <- data.frame(rt = chrom.data.item1@rtime, int= chrom.data.item1@intensity)
      chrom.data.item1.df$acquisitionNumName <- rownames(chrom.data.item1.df)
      chrom.data.item1.df <- data.frame(chrom.data.item1.df, fData(ChromPeaks.data) )
      chrom.df <- chrom.data.item1.df
      
      max.int <- max(chrom.data.item1.df$int) * (percent.limit/100)
      #max.pks <- max(chrom.data.item1.df$originalPeaksCount) * (percent.limit/100)
      max.pks <- 1

      cat('\n\n#### Inspecting the chromatogram and selecting scans based on parameters:' , '\n\n')
      cat('\n#### Intensity > ', max.int , '\n\n')
      #cat('\n#### Total Peaks > ', max.pks , '\n\n')

      temp.chrom.data <- chrom.data.item1.df %>% dplyr::select(int, originalPeaksCount) %>% 
                          dplyr::filter(int > max.int) %>% 
                          dplyr::filter(originalPeaksCount > max.pks)
      
      temp.visual.df <- chrom.data.item1.df %>% dplyr::select(rt,int) %>% dplyr::mutate(cluster = 0)
      temp.visual.df[rownames(temp.chrom.data),"cluster"] <- 1
      
      cat('\n\n#### From a total of ',base::nrow(chrom.data.item1.df), " scans, were selected: ", base::nrow(temp.chrom.data), '\n\n')
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
      ':   Total scans = ', base::nrow(chrom.data.item1.df),'. Selected = ', base::nrow(temp.chrom.data)),file=log.file,append=TRUE)
      
      
      cat('\n\n### Selected scans ', '\n\n')
      p1 <- ggplot2::ggplot(temp.visual.df, ggplot2::aes(rt, int, color = factor(cluster) ) )+
        ggplot2::geom_path(ggplot2::aes(group = 1),linewidth=0.8) +
        ggplot2::scale_color_manual(values = c("0" = "lightgray", "1" = "blue"))+
        ggplot2::labs(title="Selected scans in blue",
              x ="intensity", y = "retention time", color = "Type") + 
        ggplot2::theme_bw() 
      print(p1)

      cat('\n\n#### The selected scans have different numbers of peaks and different intensities, the arbitrary choice of groups can lead to a statistical difference between the triplicates. Therefore, we need to distribute the scans in each replicate so that there is no statistically significant difference between the groups.', '\n\n')
      
      ## --- temp
      #((hist(temp.chrom.data$int)))
      #cat('\n\n### Criando 3 grupos de scans balanceados para formar as triplicatas. ', '\n\n')
      ## --- temp
      
      # ## --- temp
      # 
      # serial.reps <- (rep(c(rep(1, length.out= nrow(temp.chrom.data)/3), 
      #                       rep(2, length.out= nrow(temp.chrom.data)/3),
      #                       rep(3, length.out= nrow(temp.chrom.data)/3)), length.out= nrow(temp.chrom.data)))
      # 
      # cat('\n\n### Resultado antes a clusterização ', '\n\n')
      # boxplot(log2(int)~ serial.reps ,data=temp.chrom.data, main="Distribuição das intensidades nas triplicatas formadas")
      # 
      # ## --- temp
      
      temp.chrom.data$cluster <- anticlust::anticlustering(
        temp.chrom.data, 
        K = 3)
      #anticlust::plot_clusters(temp.chrom.data[,1:2], clusters = temp.chrom.data$cluster)
      
      # ## --- temp
      # cat('\n\n### Resultado apos a clusterização ', '\n\n')
      # boxplot(log2(int)~cluster,data=temp.chrom.data, main="Distribuição das intensidades nas triplicatas formadas")
      # ## --- temp
      
      chrom.data.item1.df <- data.frame(cluster = temp.chrom.data$cluster, chrom.data.item1.df[rownames(temp.chrom.data),])
      ChromPeaks.data <- xcms::filterAcquisitionNum(ChromPeaks.data, chrom.data.item1.df$acquisitionNum)
      
      cat('\n\n### Balanced distribution of scans (in triplicate) on the chromatogram: ', '\n\n')
      
      chrom.df$cluster <- 0
      chrom.df[rownames(temp.chrom.data), "cluster"] <- temp.chrom.data$cluster
      p2 <- ggplot2::ggplot(chrom.df, ggplot2::aes(rt, int, color = factor(cluster) ) )+
        ggplot2::geom_path(ggplot2::aes(group = 1),linewidth=0.8) +
        ggplot2::scale_color_manual(values = c("0" = "lightgray", "1" = '#00AFBB', "2" = '#E7B800', 
                                         "3" = '#FC4E07'))+
        ggplot2::labs(title="Triplicates (group of scans) selected in the chromatogram",
              x ="retention time", y = "intensity", color = "Replicate") + 
        ggplot2::theme_bw() 
      print(p2)
      cat('\n\n')
      #, , 
      #save replicates scans
      #verify scans order:
      if (all.equal(base::rownames(Biobase::fData(ChromPeaks.data)), base::rownames(chrom.data.item1.df)) == TRUE){
        Biobase::fData(ChromPeaks.data)$cluster <- chrom.data.item1.df$cluster
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
        ':   Make replicates: OK'),file=log.file,append=TRUE)
        
        
      }else{
        message("# Error in fData")
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
        ':*** Error in fData'),file=log.file,append=TRUE)
      }
       
    }else{
      #no replicates:
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
      ':   No replicates'),file=log.file,append=TRUE)
      Biobase::fData(ChromPeaks.data)$cluster <- 1
    }

    comSpec <- MSnbase::combineSpectra(ChromPeaks.data, ppm = input.ppm,
                                #intensityFun = median, mzFun = median,
                                intensityFun = base::mean, mzFun = base::mean,
                                fcol = "cluster")

    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
      ':   Writing spectra files'),file=log.file,append=TRUE)
  
    if (input.msresolution=="high.res"){
      for (hi in 1:max(Biobase::fData(ChromPeaks.data)$cluster)){
        spc.filename <- paste0((basename(samples.info$sample[file])),"_", fData(comSpec[hi])$cluster,".mzML" )
        
        cur_rep <- comSpec[hi]
        max_peak_int <- max(intensity(comSpec[1])[[1]])
        cur_rep.limit <- max(intensity(comSpec[1])[[1]]) * (input.Tresh.RA / 100)
        
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
          ':   Max peak intensity = ', formatC(max_peak_int,digits=2,format="f") , 
          ".   Removing peaks below intensity of ",  formatC(cur_rep.limit,digits=2,format="f")),file=log.file,append=TRUE)
        
        filter.cur_rep <- MSnbase::removePeaks(cur_rep, t=cur_rep.limit)
        filter.cur_rep <- MSnbase::clean(filter.cur_rep, all=TRUE)

        file.remove(paste0(output.folder, spc.filename))
        try(MSnbase::writeMSData(object = as(filter.cur_rep, "MSnExp"), verbose = TRUE,
                         copy = TRUE,
                         file = paste0(output.folder, spc.filename) ),silent=FALSE)

        status.files <- rbind(status.files, c(samples.info$sample[file],
                                        spc.filename))
        
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
        ':   Replicate: ',spc.filename, " saved."),file=log.file,append=TRUE)

      }
      
    }else{

      for (lo in 1:max(Biobase::fData(ChromPeaks.data)$cluster)){
        spc.filename <- paste0((basename(samples.info$sample[file])),"_",
                         fData(comSpec[lo])$cluster,".mzML" )
        
        cur_rep <- comSpec[lo]
        max_peak_int <- max(intensity(comSpec[1])[[1]])
        cur_rep.limit <- max(intensity(comSpec[1])[[1]]) * (input.Tresh.RA / 100)
        
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
          ':   Max peak intensity = ', formatC(max_peak_int,digits=2,format="f") , 
          ".   Removing peaks below intensity of ",  formatC(cur_rep.limit,digits=2,format="f")),file=log.file,append=TRUE)
        
        filter.cur_rep <- MSnbase::removePeaks(cur_rep, t=cur_rep.limit)
        filter.cur_rep <- MSnbase::clean(filter.cur_rep, all=TRUE)
      
        file.remove(paste0(output.folder, spc.filename))
        
        try(MSnbase::writeMSData(object = as(filter.cur_rep, "MSnExp"), verbose = TRUE,
                               copy = TRUE,
                               file = paste0(output.folder, spc.filename) ),silent=FALSE)
        status.files <- rbind(status.files, c(samples.info$sample[file],
                                              spc.filename))
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
        ':   Replicate: ',spc.filename, " saved."),file=log.file,append=TRUE)
              
      }
    }
}

if ( nrow(status.files) > 0 ){
  colnames(status.files) <- c("sample", "replicate.file")
  n.error.files <- nrow(status.files[status.files$replicate.file %in% "error",])
}else{
  script.error <- TRUE
}

save(    data.folder,
         samples.info,
         status.files,
         n.error.files,
         file=paste0(data.folder, "variables_step_2.Rda") 
     )



#if (script.error == TRUE | nrow(status.files) == 0 ){
if ( script.error == TRUE | n.error.files == nrow(status.files) ) {
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
           ':*** None of the files can be processed *** '),file=log.file,append=TRUE)
  cat('\n\n## Error: None of the files can be processed', '\n\n')
  knitr::knit_exit()
}else{
  
  status.files <- status.files[ !(status.files$replicate.file %in% "error"), ]
  
  merged.status.files <- merge(status.files, samples.info, by="sample", all.x = TRUE)
  rownames(merged.status.files) <- merged.status.files$replicate.file 
  
  samples.info <- samples.info[ samples.info$sample %in% unique(merged.status.files$sample) , ]
  
}


```

..........


```{r, echo=FALSE,warning=FALSE,message=FALSE,fig.pos='H',fig.align='center',out.width='100%',fig.height=5,fig.width=9, results='asis'}

#################
################# Process - step 2
#################

set.seed(12345)
    save(    data.folder,
             samples.info,
             status.files,
             merged.status.files,
             file=paste0(data.folder, "variables_step_2.Rda") 
         )
    
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
': --------------------------------------------------'),file=log.file,append=TRUE)
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
': Second step'),file=log.file,append=TRUE)

BiocParallel::register(BiocParallel::SerialParam())
processed.sps <- Spectra::Spectra(paste0(output.folder,merged.status.files$replicate.file), backend = Spectra::MsBackendMzR())

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
      ': Binning'),file=log.file,append=TRUE)
processed.sps.bin <- Spectra::bin(processed.sps, binSize = input.binSize)
invisible(gc())

################
################  --- extracting mz and int
################

sps.mzs <- list()
for (i in 1:length(processed.sps.bin)){
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Extracting mz: ', i, " of ", length(processed.sps.bin)),file=log.file,append=TRUE)
  sps.mzs[[i]] <- data.frame(mz = Spectra::mz(processed.sps.bin[i])[[1]], 
                             intensity = Spectra::intensity(processed.sps.bin[i])[[1]] ) |> 
                  subset(intensity!=0) |> getElement("mz")
  invisible(gc())
  
}
unique.sps.mzs <- unique(Reduce(c,sps.mzs))
sps.bin.df <- setNames(data.frame(matrix(ncol = length(unique.sps.mzs), nrow = length(processed.sps.bin))), c(unique.sps.mzs))
for (i in 1:length(processed.sps.bin) ){
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Extracting intensity: ', i, " of ", length(processed.sps.bin)),file=log.file,append=TRUE)
  temp.df <- data.frame(mz = Spectra::mz(processed.sps.bin[i])[[1]], 
                             intensity = Spectra::intensity(processed.sps.bin[i])[[1]] ) |> 
              subset(intensity!=0)
  message("item ", i, ":  ", length(temp.df$intensity), " intensities - and mzs: ", length(as.character(temp.df$mz)))

  sps.bin.df[i,as.character(temp.df$mz)] <- temp.df$intensity
  
  vec.na.mz <- which(is.na(sps.bin.df[i,]))
  na.mz.names <- colnames(sps.bin.df)[vec.na.mz]
  
  #sps.bin.df[i,] <- sps.bin.df[i,]  %>%  mutate(across(where(is.numeric), ~replace(., is.na(.), 0)))
  sps.bin.df[i, na.mz.names] <- 0

  invisible(gc())
}
row.names(sps.bin.df) <- basename(processed.sps.bin$dataOrigin)
save(sps.bin.df, file=paste0(data.folder,"sps.bin.df.Rda"))

################
################  --- end of extracting mz and int
################

##############################
################# parallel ##
if(.Platform$OS.type=="windows"){ # If we are on windows
  # Snow-like functionality
  cl<- parallel::makeCluster(n.cores) # adjust according to the number of available cores (CPU)
  doParallel::registerDoParallel(cl)
}else{ # If we are on unix
  # Multi Core functionality
  doParallel::registerDoParallel(cores = n.cores)
}
#################parallel
###############################


  # write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  # ': Converting NAs to zero...' ),file=log.file,append=TRUE)
#     
# #sps.bin.df[is.na(sps.bin.df)] <- 0
# #sps.bin.df <- sps.bin.df[1:10,1:10000]
# sps.bin.df.colnames <- colnames(sps.bin.df)
# sps.no.na <- foreach::foreach(x=1:nrow(sps.bin.df),
#                            .combine = "rbind") %dopar% {
#                              
#                       cur.line <- sps.bin.df[x,]
#                       cur.line[is.na(cur.line)] <- 0
#                       
#                       if (x == floor((20/100)*nrow(sps.bin.df) ) | x == floor((50/100)*nrow(sps.bin.df)) | x == floor((80/100)*nrow(sps.bin.df))  ){
#                           write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
#                           ':    -  ',  formatC( (x/nrow(sps.bin.df))*100,digits=2,format="f"), "%"),
#                           file=log.file,append=TRUE)
#                       }
# 
#                       data.frame( cur.line )
#                   }

  # write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  # ':    -  100%'),
  # file=log.file,append=TRUE)
  
  #write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  #': Finishing the binning process...' ),file=log.file,append=TRUE)

  #sps.bin.df <- sps.no.na
  #colnames(sps.bin.df) <- sps.bin.df.colnames
  #rm(sps.no.na)

#############################################################

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Removing null columns...' ),file=log.file,append=TRUE)

sps.bin.df <- sps.bin.df[, colSums(sps.bin.df != 0, na.rm = TRUE) > 0] 

if (input.binSize>=1){
  colnames(sps.bin.df) <- trunc(as.numeric( colnames(sps.bin.df) ))
}
invisible(gc())
if (ncol(sps.bin.df) >= 2){

  if (input.make.heatmaps == "TRUE"){
    cat('\n\n## Heatmap (raw data) \n\n') 
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
    ': Creating heatmap: ', ncol(sps.bin.df), " number of columns" ),file=log.file,append=TRUE)
    heatmap(as.matrix(sps.bin.df))
  }

}


write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
': Binning: OK'),file=log.file,append=TRUE)

sps.bin.df <- sps.bin.df %>% dplyr::relocate(order(as.numeric(names(.))))

processed.sps.bin.df <- sps.bin.df
rownames(processed.sps.bin.df) <-  basename(processed.sps$dataOrigin)
#all.equal(basename(processed.sps$dataOrigin) , merged.status.files$replicate.file )

df.export <- data.frame(samples = rownames(processed.sps.bin.df), 
                        class = as.character(merged.status.files[rownames(processed.sps.bin.df),"class"]), 
                        processed.sps.bin.df)
colnames(df.export)[3:ncol(df.export)] <- (as.numeric(colnames(processed.sps.bin.df)))

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Exporting processed data '),file=log.file,append=TRUE)
write.table(x = df.export,file = paste0(data.folder, "Data","_metaboanalyst.csv"), sep=",", row.names=FALSE, quote = F)
save(df.export, file=paste0(data.folder,"df.export.Rda"))

cat('\n\n File exported to: ', paste0(data.folder, "Data","_metaboanalyst.csv") ,'  \n\n') 


names(cores)[1:length(unique(df.export$class))] <- unique(df.export$class)

#---------- pca
cat('\n\n## PCA \n\n') 

pca <- prcomp(df.export[,3:ncol(df.export)], scale = TRUE)
scores <- as.data.frame(pca$x)
scores$class <- df.export$class

pca.pecents <- pca$sdev^2/sum(pca$sdev^2)*100
pca.pecents.df <- data.frame(PC = paste0("PC", 1:length(pca.pecents)), Porcentagem = pca.pecents)

plot.pca <- ggplot2::ggplot(scores, aes(x = PC1, y = PC2, color = class)) +
  ggplot2::geom_point(size = 3) +
  scale_color_manual(values = cores ) +
  ggplot2::xlab(paste0("PC1 (", round(pca.pecents[1], 1), "%)")) +
  ggplot2::ylab(paste0("PC2 (", round(pca.pecents[2], 1), "%)")) +
  ggplot2::labs(title = "PCA")+ 
  ggplot2::theme_bw()
print(plot.pca)

#----------- end of pca

#----------- mean of data

df.export.mean <- df.export %>% 
                  dplyr::group_by(class) %>%
                  dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean))
invisible(gc())

#----------- end of mean of data

################
################  --- plot mean spectra
################
#---------- processed mean spectra


df.export.class.mean <- S4Vectors::DataFrame(
    msLevel = c(rep(1L,nrow(df.export.mean))),
    polarity = c(rep(1L,nrow(df.export.mean))),
    id = df.export.mean$class,
    name = df.export.mean$class)

## Assign m/z and intensity values.
df.export.class.mean$mz <- rep(list(as.numeric(colnames(df.export.mean[,3:ncol(df.export.mean)]))), nrow(df.export.mean))
df.export.class.mean$intensity <- lapply(as.data.frame(t(df.export.mean[,3:ncol(df.export.mean)])), unlist)

obj.df.export.class.mean <- Spectra::Spectra(df.export.class.mean)

########### end processed spectra -----

cat('\n\n## Spectra plot (raw data)  \n\n') 

Spectra::plotSpectraOverlay(obj.df.export.class.mean, lwd = 2, col = cores[unique(df.export.mean$class)],
                            main="Mean spectra of classes orverlay")
legend("topleft", col = cores[unique(df.export.mean$class)], legend = obj.df.export.class.mean$name, pch = 15)

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Plotting mean spectra per class'),file=log.file,append=TRUE)
for (m in 1:nrow(df.export.mean)){
  Spectra::plotSpectra(obj.df.export.class.mean[m], lwd = 2, col = cores[obj.df.export.class.mean$name[m]],
                              main=obj.df.export.class.mean$name[m] )
  legend("topleft", col = cores[obj.df.export.class.mean$name[m]], legend = obj.df.export.class.mean$name[m], pch = 15)
}

################
################  --- end if processed mean spectra
################


################
################  --- replicate filter
################


if (input.replicate.filter == "TRUE"){
  
cat('\n\n## Analyze replicates  \n\n')
cat('#### Process to evaluate features of replicates.','\n\n')
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Analyze replicates. Limit = ',input.value.replicate.filter, "%"  ),file=log.file,append=TRUE)

df.export.bkp <- df.export


df.replicate.result <- data.frame()
n.total.features.replicate <- ncol(df.export)-2
#input.value.replicate.filter <- 80

df.export.with.replicates <- df.export %>%
        dplyr::mutate(replicate = as.character(merged.status.files[rownames(df.export),"replicate"])) %>% 
        dplyr::relocate(replicate)

replicate.filter.features <- df.export.with.replicates %>%
        dplyr::group_by(replicate) %>%
        dplyr::summarise(dplyr::across(dplyr::where(is.numeric), ~sum(. > 0)/sum(!is.na(.)) )) 

holder <- foreach::foreach(x=1:length(replicate.filter.features$replicate),
                  .combine = "c", .packages='dplyr') %dopar% {

  item.replicate <- replicate.filter.features$replicate[x]
  item.replicate.name <- paste("'",as.character(
                      unique(merged.status.files[merged.status.files$replicate==item.replicate,"sample"])))
    
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Analyzing replicate ', item.replicate,
               " = ",item.replicate.name,"'",collapse=", ",sep=""),file=log.file,append=TRUE )
  
  replicate.exclude.features <- replicate.filter.features %>%
    dplyr::filter(replicate == item.replicate) %>%
    dplyr::select_if(~ . < (input.value.replicate.filter/100)) %>% colnames()

    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
    ':    -  Removing ', length(replicate.exclude.features), " features from ", as.character(item.replicate) ),file=log.file,append=TRUE)
  
  list(c(item.replicate, replicate.exclude.features))
}


#save(holder,df.export,merged.status.files, file=paste0(data.folder,"holder.Rda"))
invisible(gc())
  
for(list.item in holder){
  
  if (length(list.item) == 1){
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
    ':    -  0 features to remove from ', list.item[1]),file=log.file,append=TRUE)
  }else{
    item.replicate <- list.item[1]
    replicate.exclude.features <- list.item[2:length(list.item)]
    df.export.with.replicates[df.export.with.replicates$replicate==item.replicate, replicate.exclude.features] <- 0
    df.replicate.result <- rbind(df.replicate.result,
                                 c(item.replicate,
                                  length(replicate.exclude.features),
                                  formatC((length(replicate.exclude.features) / n.total.features.replicate)*100,
                                          digits=2,format="f")) )
    
  }

}

  df.export <- subset(df.export.with.replicates, select = -c(replicate) )

if (nrow(df.replicate.result) > 0){
  colnames(df.replicate.result) <- c("Replicate", "Features removed", "Removal percentage (%)")
  print_paged_df(df.replicate.result)
}else{
  cat('\n\n### No features have been removed.  \n\n') 
}

  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Exporting replicates filtered data '),file=log.file,append=TRUE)
  write.table(x = df.export,
              file = paste0(data.folder,"Data","_metaboanalyst_replicates_filtered_",input.value.replicate.filter,".csv"), 
              sep=",", row.names=FALSE, quote = F)
  cat('\n\n File exported to: ', paste0(data.folder,"Data","_metaboanalyst_replicates_filtered_",input.value.replicate.filter,".csv") ,'  \n\n') 


} #end of replicate filter

################
################  --- end of replicate filter
################

#df.export[,3:ncol(df.export)] <- df.export[,3:ncol(df.export)] / 100000
#load("~/r_develop/TENGI/df.export.Rda")

df.export.mean <- df.export %>% 
                  dplyr::group_by(class) %>%
                  dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean))
invisible(gc())

######################################################
# filtrar os picos do branco:
# Remover os ions do branco que tenham uma intensidade > 1/3  nas amostras

################
################  --- blank remove
################

if (input.subtract.group != ""){
  
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Subtracting ions from ', input.subtract.group ),file=log.file,append=TRUE)

cat('\n\n## Subtraction procedure \n\n') 
cat('#### Subtraction of the ', input.subtract.group ,' ions present in the dataset.', 
    'The procedure analyzes the intensity ratio of the samples divided by ',input.subtract.group,'group. If the ratio is less than ', input.min.fold ,' (minimum fold change), the ion is removed. ','\n\n')

#write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Removing the ions from ', input.subtract.group ),file=log.file,append=TRUE)
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Minimum fold change: ', input.min.fold ),file=log.file,append=TRUE)

vector.blank.mean <- as.numeric(subset(df.export.mean,class==input.subtract.group, select = -c(class)) )
df.blank.remove <- data.frame()
n.total.features.replicate <- ncol(df.export)-2

df.export.info <- df.export %>%
        dplyr::mutate(replicate = as.character(merged.status.files[rownames(df.export),"replicate"]) ) %>% 
        dplyr::relocate(replicate) %>% dplyr::select(samples,class, replicate)

df.export.replicate.mean <- df.export %>%
        dplyr::mutate(replicate = as.character(merged.status.files[rownames(df.export),"replicate"]) ) %>% 
        dplyr::relocate(replicate) %>% 
        dplyr::filter(class!=input.subtract.group) %>% 
        dplyr::group_by(replicate) %>%
        dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean))

compare.blank.mean <- df.export.replicate.mean[,2:ncol(df.export.replicate.mean)] %>%
                      plyr::adply(.,1, function(u) ( ( u  /  vector.blank.mean ) < input.min.fold ) )
df.features <- colnames(compare.blank.mean)

for(i in 1:nrow(df.export.replicate.mean)){
  blank.ions <- integer()
  i.replicate <- df.export.replicate.mean$replicate[i]
  blank.ions <-  which( compare.blank.mean[i,] == TRUE  )
   
  if ( length(blank.ions) > 0) {
    
    df.export[df.export$samples %in% df.export.info[df.export.info$replicate==i.replicate, "samples"], df.features[blank.ions] ] <- 0
    
    df.blank.remove <- rbind(df.blank.remove,
                             c(i.replicate,
                               length(blank.ions),
                               formatC((length(blank.ions) / n.total.features.replicate)*100,
                                       digits=2,format="f")) )
    
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
    ':    -  Removing ', length(blank.ions), " ions from replicate ", i.replicate),file=log.file,append=TRUE)
  }

}


data_filtered <- df.export %>% dplyr::filter(class!=input.subtract.group)

write.table(x = data_filtered,
              file = paste0(data.folder, "Data_substracted_", input.min.fold ,"_MFC_metaboanalyst.csv"), sep=",", row.names=FALSE, quote = F)

cat('\n\n File exported to: ', paste0(data.folder, "Data_substracted_", input.min.fold ,"_MFC_metaboanalyst.csv") ,'  \n\n') 

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Subtraction procedure: OK ' ),file=log.file,append=TRUE)

  if (nrow(df.blank.remove) > 0){
    colnames(df.blank.remove) <- c("Replicate", "Features removed", "Removal percentage (%)")
    print_paged_df(df.blank.remove)
  }else{
    cat('\n\n### No features have been removed.  \n\n') 
  }

df.export <- data_filtered
df.export[is.na(df.export)] <- 0

}

################
################  --- end of blank remove
################


#clean zero cols from data -----------------------
df.export <- df.export[, colSums(df.export != 0, na.rm = TRUE) > 0] 
#-------------------------------------------------

################
################  --- Class filter
################

n.total.classes <- length(unique(df.export$class))

if (input.class.mean == "TRUE" & (n.total.classes > 0) ){

  cat('\n\n## Filter with-in class  \n\n') 
#cat('#### Filtration of ions by class consists of removing ions, within each class, that are not present in at least ',input.class.mean.filter,'% of the samples #of the respective class.','\n\n')
 
  cat('#### Procedure to filter ions by class, remove ions from each class that are present in less than ',input.class.mean.filter,'% of the samples within that class.', '\n\n')
 
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Filtration of ions by class. Limit = ', input.class.mean.filter,"%" ),file=log.file,append=TRUE)
  
df.export.bkp <- df.export

class.filter.features <- df.export %>%
        dplyr::mutate(replicate = as.character(merged.status.files[rownames(df.export),"replicate"]) ) %>% 
        dplyr::relocate(replicate) %>% 
        dplyr::group_by(class, replicate) %>%
        dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean)) %>% 
        dplyr::select(-replicate) %>% 
        dplyr::group_by(class) %>%
        dplyr::summarise(dplyr::across(dplyr::where(is.numeric), ~sum(. > 0)/sum(!is.na(.)) )) 

invisible(gc())
df.class.result <- data.frame()
n.total.features.class <- ncol(df.export)-2

class.holder <- foreach::foreach(x=1:length(class.filter.features$class),
                           .combine = "c", .packages='dplyr') %dopar% {
                             
                      item.class <- class.filter.features$class[x]
                      
                      class.exclude.features <- class.filter.features %>%
                        dplyr::filter(class == item.class) %>%
                        dplyr::select_if(~ . < (input.class.mean.filter/100)) %>% colnames()
                      
                      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
                      ':    -  Removing ', length(class.exclude.features), " features from ", item.class),file=log.file,append=TRUE)
                      
                      list(c(item.class, class.exclude.features))
                  }

invisible(gc())

for(list.item in class.holder){
  if (length(list.item) == 1){
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
                 ':    -  0 features to remove from ', list.item[1]),file=log.file,append=TRUE)
  }else{
    item.class <- list.item[1]
    class.exclude.features <- list.item[2:length(list.item)]
    df.export[df.export$class==item.class, class.exclude.features] <- 0
    df.class.result <- rbind(df.class.result,
                             c(item.class,
                              length(class.exclude.features),
                              formatC( ( length(class.exclude.features) / n.total.features.class)*100,
                                      digits=2,format="f")) )

  }
}

invisible(gc())
#clean zero cols from data -----------------------
df.export <- df.export[, colSums(df.export != 0, na.rm = TRUE) > 0] 
#-------------------------------------------------

if ( nrow(df.class.result) > 0){
  colnames(df.class.result) <- c("Class", "Features removed", "Removal percentage (%)")
  print_paged_df(df.class.result) 
}else{
  cat('\n\n### No features have been removed.  \n\n') 
  df.export<-df.export.bkp
  rm(df.export.bkp)
}


if (ncol(df.export)==2){
  
  cat('\n\n### Filter with-in class: No feature has been selected. 
               This occurs for very high percentage values  \n\n') 
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Filter with-in class: No feature has been selected. 
               This occurs for very high percentage values'),file=log.file,append=TRUE)
  
  df.export <- df.export.bkp
  
}else{

  if (ncol(df.export) > 3){
    #class.filtered.hm <- class.filtered.df[,3:ncol(class.filtered.df)]
    class.filtered.hm <- subset(df.export, select = -c(samples, class))
    class.filtered.hm[is.na(class.filtered.hm)] <- 0
    #zeros <- colSums(class.filtered.hm) == 0
    #class.filtered.hm <- subset(class.filtered.hm, select = !c(zeros))
    
    if (input.make.heatmaps == "TRUE"){
      cat('\n\n## Heatmap (class filtered) \n\n') 
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
        ': Creating heatmap: ', ncol(class.filtered.hm), " number of columns" ),file=log.file,append=TRUE)
      heatmap(as.matrix(class.filtered.hm), labRow=df.export$class)
    }

    #---------- pca
    cat('\n\n## PCA (filter with-in class) \n\n') 
    pca <- prcomp(class.filtered.hm, scale = TRUE)
    scores <- as.data.frame(pca$x)
    scores$class <- df.export$class
    
    pca.pecents <- pca$sdev^2/sum(pca$sdev^2)*100
    pca.pecents.df <- data.frame(PC = paste0("PC", 1:length(pca.pecents)), Porcentagem = pca.pecents)
    
    plot.pca <- ggplot2::ggplot(scores, aes(x = PC1, y = PC2, color = class)) +
    ggplot2::geom_point(size = 3) +
    scale_color_manual(values = cores ) +
    ggplot2::xlab(paste0("PC1 (", round(pca.pecents[1], 1), "%)")) +
    ggplot2::ylab(paste0("PC2 (", round(pca.pecents[2], 1), "%)")) +
    ggplot2::labs(title = "PCA after filter with-in class")+ 
    ggplot2::theme_bw()
    print(plot.pca)
    #----------- end of pca
  
  }


  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Exporting filtered data per class'),file=log.file,append=TRUE)
  write.table(x = df.export,
              file = paste0(data.folder,"Data","_metaboanalyst_class_filtered_",input.class.mean.filter,".csv"), 
              sep=",", row.names=FALSE, quote = F)
  cat('\n\n File exported to: ', paste0(data.folder,"Data","_metaboanalyst_class_filtered_",input.class.mean.filter,".csv") ,'  \n\n') 

}
  
}

################
################  --- end of Class filter
################

```


```{r, echo=FALSE,warning=FALSE,message=FALSE,fig.pos='H',fig.align='center',out.width='100%',fig.height=5,fig.width=9, results='asis'}

if ( n.total.classes > 0 ){

df.export.mean <- df.export %>% 
                  dplyr::group_by(class) %>%
                  dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean))
invisible(gc())

################
################  --- plot mean spectra - afte processing
################

df.export.class.mean <- S4Vectors::DataFrame(
    msLevel = c(rep(1L,nrow(df.export.mean))),
    polarity = c(rep(1L,nrow(df.export.mean))),
    id = df.export.mean$class,
    name = df.export.mean$class)

## Assign m/z and intensity values.
df.export.class.mean$mz <- rep(list(as.numeric(colnames(df.export.mean[,3:ncol(df.export.mean)]))), nrow(df.export.mean))
df.export.class.mean$intensity <- lapply(as.data.frame(t(df.export.mean[,3:ncol(df.export.mean)])), unlist)

obj.df.export.class.mean <- Spectra::Spectra(df.export.class.mean)

########### end processed spectra -----

cat('\n\n## Spectra plot (processed data)  \n\n') 

Spectra::plotSpectraOverlay(obj.df.export.class.mean, lwd = 2, col = cores[unique(df.export.mean$class)],
                            main="Mean spectra of classes orverlay")
legend("topleft", col = cores[unique(df.export.mean$class)], legend = obj.df.export.class.mean$name, pch = 15)

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Plotting mean spectra per class'),file=log.file,append=TRUE)
for (m in 1:nrow(df.export.mean)){
  Spectra::plotSpectra(obj.df.export.class.mean[m], lwd = 2, col = cores[obj.df.export.class.mean$name[m]],
                              main=obj.df.export.class.mean$name[m] )
  legend("topleft", col = cores[obj.df.export.class.mean$name[m]], legend = obj.df.export.class.mean$name[m], pch = 15)
}

################
################  --- end if processed mean spectra
################
}

```


```{r, echo=FALSE,warning=FALSE,message=FALSE,fig.pos='H',fig.align='center',out.width='100%',fig.height=5,fig.width=9, results='asis'}
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': END' ),file=log.file,append=TRUE)
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Session parameters:' ),file=log.file,append=TRUE)
write.table(format(session.parameters),file=log.file, append = TRUE, col.names = F)

#Stop cluster
parallel::stopCluster(cl)

```







