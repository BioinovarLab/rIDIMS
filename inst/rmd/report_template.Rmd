---
title: 'rIDIMS: An R Package for Processing Intermittent and Direct Injection Mass Spectrometry Data'
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
---

```{r setup, include=FALSE,echo=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE) 
set.seed(12345)
print_paged_df <- function(...) {
cat(rmarkdown:::print.paged_df(rmarkdown::paged_table(...,options = list(rows.print = 5))))
}

```



```{r,echo=FALSE}

make.replicates <- input.replicates
aggregationFun <- input.aggregationFun
percent.limit <- input.chr.limit
Tresh.RA <- input.Tresh.RA
script.error <- FALSE

cores <- c('#000000', '#FFC800', '#0077C8', '#F56A00', '#9B59B6', '#A3A3A3', '#00BFFF', '#F5D800', '#7F8C8D', '#7CFC00', '#EE82EE', '#00CED1', '#FF4500', '#DA70D6', '#FFA500', '#008080', '#1E90FF', '#8B008B', '#808000', '#FF69B4', '#8A2BE2', '#D2691E', '#FFD700', '#800080', '#008000', '#DC143C', '#4169E1', '#00FF7F', '#FF1493', '#FF00FF')

#clean output
invisible( unlink(paste0(output.folder,"*"), recursive = TRUE, force = TRUE) )

### setup
log.file <- paste0(data.folder,"log_", report.serial , ".txt")
invisible( file.remove(log.file) )
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"), ": Log started"),file=log.file,append=TRUE)
#write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"), ": Session parameters"),file=log.file,append=TRUE)
#write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"), print(session.parameters,right=F)),file=log.file,append=TRUE)
BiocParallel::register(BiocParallel::SerialParam())


## rIDIMS: An R Package For Processing Intermitent and Direct Injection Mass Spectrometry Data


```

Mass spectrometry-based metabolomics, primarily direct injection MS and ambient ionization approaches, allows fast, high-throughput analyses, enabling the detection of more than thousands of metabolites without the need for prior separation and extenuating sample preparation. After data acquisition, feature selection is a crucial step in untargeted metabolomic and fingerprint analysis. However, it can be challenging as low-quality and unreliable features can often be introduced to the data by signal drop-out, ion suppression effects, and background signals. Mass spectra pre-processing is essential to selecting high-quality features, leading to more accurate and reliable data for further statistical analysis. rIDIMS offers a simple and fast workflow to process two-dimensional mass spec data by selecting high-quality scans and features based on mass spectrum intensity, data alignment, filtering reproducible ions along sample replicates, removing background ions, and selecting ions that are more representative per class. Each pre-processing step is data-adaptive and can be visualized in this report for user evaluation.

  

```{r,echo=FALSE,warning=FALSE,message=FALSE,fig.pos='H',fig.align='center',out.width='100%',fig.height=5,fig.width=9, results='asis'}

#################
################# Process - step 1 
#################


cat('\n\n## Setting Parameters', '\n')

  if (input.msresolution=="high.res"){
    message("- high resolution mode ")
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
             ': high resolution mode'),file=log.file,append=TRUE)
    cat('\n\n### High-Resolution Data', '\n')
  }else{
    message("- low resolution mode ")
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
     ': low resolution mode'),file=log.file,append=TRUE)
    cat('\n\n### Low-Resolution Data', '\n')
  }

cat('\n\n * Bin size: ', as.numeric(session.parameters[2,1]) , '\n')
cat('\n\n * Signal Noise Ratio (SNR) threshold: ', as.numeric(session.parameters[3,1]) , '\n')
cat('\n\n * ppm for grouping of mass peaks: ',as.numeric( session.parameters[6,1]) , '\n')

cat('\n\n## Processing the files', '\n')

if (make.replicates == "TRUE"){

  cat('\n\n### Make Spectra Replicates', '\n')
  cat('\n\n The selected scans have different numbers of peaks and different intensities. The arbitrary choice of groups can lead to a statistical difference between the triplicates. Therefore, we need to distribute the scans in each replicate so that there is no statistically significant difference between the created replicates. ' , '\n')

}

status.files <- data.frame()

for (file in 1:nrow(samples.info) ) {
  
  cat('\n\n## Working on:', samples.info$sample[file], '\n\n')
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
               ':## Working on: ', samples.info$sample[file]),file=log.file,append=TRUE)
  
  fine.xcms.data <- try(xcms.data <- MSnbase::readMSData(samples.info$file.dir[file], 
                                                         mode = "onDisk", #msLevel. = 1L, 
                                                         centroided. = TRUE),silent=FALSE)
  
  if ( class(fine.xcms.data) == "try-error"){
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
               ':*** Error in ', samples.info$sample[file]),file=log.file,append=TRUE)
      status.files <- rbind(status.files, c(samples.info$sample[file],
                                      "error"))
      cat('\n#### File processing error ' , '\n\n')
    next
  }
  
  if (is.null(xcms.data@featureData@data[["msLevel"]])==TRUE){
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
               ':*** Error in ', samples.info$sample[file]),file=log.file,append=TRUE)
      status.files <- rbind(status.files, c(samples.info$sample[file],
                                      "error"))
      cat('\n#### File processing error ' , '\n\n')
    next
  }
  
  
  #Shimadzu direct infusion bug correction:
  if ( sum(xcms.data@featureData@data[["msLevel"]]) == 0) {
    xcms.data@featureData@data[["msLevel"]] <- 1L
  }
  
  xcms.data <- MSnbase::filterMsLevel(xcms.data, msLevel. = 1L)
  xcms.data <- MSnbase::filterEmptySpectra(xcms.data)
  
  if (input.msresolution=="high.res"){
    #vector.input.scales <- base::strsplit(input.scales,",")[[1]]
    mfp <- xcms::MatchedFilterParam(binSize = 0.01)
    xcms::snthresh(mfp) <- input.snthresh
    ChromPeaks.data <- xcms::findChromPeaks(xcms.data, param=mfp)
  }else{
    mfp <- xcms::MatchedFilterParam(binSize = 0.01)
    xcms::snthresh(mfp) <- input.snthresh
    ChromPeaks.data <- xcms::findChromPeaks(xcms.data, param=mfp)
  }

  #make replicates and/or combine:
    if (make.replicates == "TRUE"){
      message(" making replicates ... ")
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
       ':   Make replicates'),file=log.file,append=TRUE)
    
    if (debug_app==TRUE){
      save(ChromPeaks.data,
         aggregationFun,percent.limit,
         log.file,
         file=paste0(data.folder, "variables_step_inside.Rda") 
     )
    }


      
      chrom.data <- xcms::chromatogram(ChromPeaks.data, aggregationFun = aggregationFun)
      chrom.data.item1 <- chrom.data[1, 1]
      chrom.data.item1.df <- data.frame(rt = chrom.data.item1@rtime, int= chrom.data.item1@intensity)
      chrom.data.item1.df$acquisitionNumName <- rownames(chrom.data.item1.df)
      chrom.data.item1.df <- data.frame(chrom.data.item1.df, fData(ChromPeaks.data) )
      chrom.df <- chrom.data.item1.df
      

      
      
      max.int <- max(chrom.data.item1.df$int) * (percent.limit/100)
      #max.pks <- max(chrom.data.item1.df$originalPeaksCount) * (percent.limit/100)
      max.pks <- 1

      cat('\n\n#### Inspecting the chromatogram and selecting scans based on parameters:' , '\n\n')
      cat('\n#### Intensity > ', max.int , '\n\n')
      #cat('\n#### Total Peaks > ', max.pks , '\n\n')

      temp.chrom.data <- chrom.data.item1.df %>% dplyr::select(int, originalPeaksCount) %>% 
                          dplyr::filter(int > max.int) %>% 
                          dplyr::filter(originalPeaksCount > max.pks)
      

      
      temp.visual.df <- chrom.data.item1.df %>% dplyr::select(rt,int) %>% dplyr::mutate(cluster = 0)
      temp.visual.df[rownames(temp.chrom.data),"cluster"] <- 1
      
      cat('\n\n#### From a total of ',base::nrow(chrom.data.item1.df), " scans, were selected: ", base::nrow(temp.chrom.data), '\n\n')
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
      ':   Total scans = ', base::nrow(chrom.data.item1.df),'. Selected = ', base::nrow(temp.chrom.data)),file=log.file,append=TRUE)
      
      if (base::nrow(temp.chrom.data) == 0){
          write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
           ':*** Error in ', samples.info$sample[file]),file=log.file,append=TRUE)
          status.files <- rbind(status.files, c(samples.info$sample[file],
                                  "error"))
          cat('\n#### File processing error ' , '\n\n')
          next
      }

      
      
      cat('\n\n### Selected scans ', '\n\n')
      p1 <- ggplot2::ggplot(temp.visual.df, ggplot2::aes(rt, int, color = factor(cluster) ) )+
        ggplot2::geom_path(ggplot2::aes(group = 1),linewidth=0.8) +
        ggplot2::scale_color_manual(values = c("0" = "lightgray", "1" = "blue"))+
        ggplot2::labs(title="Selected scans in blue",
              x ="retention time", y = "intensity", color = "Type") + 
        guides(color="none")+
        ggplot2::theme_bw() 
      print(p1)

      # cat('\n\n#### The selected scans have different numbers of peaks and different intensities, the arbitrary choice of groups can lead to a statistical difference between the triplicates. Therefore, we need to distribute the scans in each replicate so that there is no statistically significant difference between the groups.', '\n\n')
      
      ## --- temp
      #((hist(temp.chrom.data$int)))
      #cat('\n\n### Criando 3 grupos de scans balanceados para formar as triplicatas. ', '\n\n')
      ## --- temp
      
      # ## --- temp
      # 
      # serial.reps <- (rep(c(rep(1, length.out= nrow(temp.chrom.data)/3), 
      #                       rep(2, length.out= nrow(temp.chrom.data)/3),
      #                       rep(3, length.out= nrow(temp.chrom.data)/3)), length.out= nrow(temp.chrom.data)))
      # 
      # cat('\n\n### Resultado antes a clusterização ', '\n\n')
      # boxplot(log2(int)~ serial.reps ,data=temp.chrom.data, main="Distribuição das intensidades nas triplicatas formadas")
      # 
      # ## --- temp
      
      temp.chrom.data$cluster <- anticlust::anticlustering(
        temp.chrom.data, 
        K = 3)
      #anticlust::plot_clusters(temp.chrom.data[,1:2], clusters = temp.chrom.data$cluster)
      
      # ## --- temp
      # cat('\n\n### Resultado apos a clusterização ', '\n\n')
      # boxplot(log2(int)~cluster,data=temp.chrom.data, main="Distribuição das intensidades nas triplicatas formadas")
      # ## --- temp
      
      chrom.data.item1.df <- data.frame(cluster = temp.chrom.data$cluster, chrom.data.item1.df[rownames(temp.chrom.data),])
      ChromPeaks.data <- xcms::filterAcquisitionNum(ChromPeaks.data, chrom.data.item1.df$acquisitionNum)
      
      cat('\n\n### Balanced distribution of scans (in triplicate) on the chromatogram: ', '\n\n')
      
      chrom.df$cluster <- 0
      chrom.df[rownames(temp.chrom.data), "cluster"] <- temp.chrom.data$cluster
      p2 <- ggplot2::ggplot(chrom.df, ggplot2::aes(rt, int, color = factor(cluster) ) )+
        ggplot2::geom_path(ggplot2::aes(group = 1),linewidth=0.8) +
        ggplot2::scale_color_manual(values = c("0" = "lightgray", "1" = '#00AFBB', "2" = '#E7B800', 
                                         "3" = '#FC4E07'))+
        ggplot2::labs(title="Triplicates (group of scans) selected in the chromatogram",
              x ="intensity", y = "retention time", color = "Replicate") + 
        ggplot2::theme_bw() 
      print(p2)
      cat('\n\n')
      #, , 
      #save replicates scans
      #verify scans order:
      if (all.equal(base::rownames(Biobase::fData(ChromPeaks.data)), base::rownames(chrom.data.item1.df)) == TRUE){
        Biobase::fData(ChromPeaks.data)$cluster <- chrom.data.item1.df$cluster
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
        ':   Make replicates: OK'),file=log.file,append=TRUE)
        
        
      }else{
        message("# Error in fData")
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
        ':*** Error in fData'),file=log.file,append=TRUE)
      }
       
    }else{
      #no replicates:
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
      ':   No replicates'),file=log.file,append=TRUE)
      Biobase::fData(ChromPeaks.data)$cluster <- 1
    }

    comSpec <- MSnbase::combineSpectra(ChromPeaks.data, ppm = input.ppm,
                                #intensityFun = median, mzFun = median,
                                intensityFun = base::mean, mzFun = base::mean,
                                fcol = "cluster")

    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
      ':   Writing spectra files'),file=log.file,append=TRUE)
  
    if (input.msresolution=="high.res"){
      for (hi in 1:max(Biobase::fData(ChromPeaks.data)$cluster)){
        spc.filename <- paste0((basename(samples.info$sample[file])),"_", fData(comSpec[hi])$cluster,".mzML" )
        
        cur_rep <- comSpec[hi]
        max_peak_int <- max(intensity(comSpec[1])[[1]])
        cur_rep.limit <- max(intensity(comSpec[1])[[1]]) * (input.Tresh.RA / 100)
        
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
          ':   Max peak intensity = ', formatC(max_peak_int,digits=2,format="f") , 
          ".   Removing peaks with intensity below ",  formatC(cur_rep.limit,digits=2,format="f")),file=log.file,append=TRUE)
        
        filter.cur_rep <- MSnbase::removePeaks(cur_rep, t=cur_rep.limit)
        filter.cur_rep <- MSnbase::clean(filter.cur_rep, all=TRUE)

        file.remove(paste0(output.folder, spc.filename))
        try(MSnbase::writeMSData(object = as(filter.cur_rep, "MSnExp"), verbose = TRUE,
                         copy = TRUE,
                         file = paste0(output.folder, spc.filename) ),silent=FALSE)

        status.files <- rbind(status.files, c(samples.info$sample[file],
                                        spc.filename))
        
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
        ':   Replicate: ',spc.filename, " saved."),file=log.file,append=TRUE)

      }
      
    }else{

      for (lo in 1:max(Biobase::fData(ChromPeaks.data)$cluster)){
        spc.filename <- paste0((basename(samples.info$sample[file])),"_",
                         fData(comSpec[lo])$cluster,".mzML" )
        
        cur_rep <- comSpec[lo]
        max_peak_int <- max(intensity(comSpec[1])[[1]])
        cur_rep.limit <- max(intensity(comSpec[1])[[1]]) * (input.Tresh.RA / 100)
        
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
          ':   Max peak intensity = ', formatC(max_peak_int,digits=2,format="f") , 
          ".   Removing peaks below intensity of ",  formatC(cur_rep.limit,digits=2,format="f")),file=log.file,append=TRUE)
        
        filter.cur_rep <- MSnbase::removePeaks(cur_rep, t=cur_rep.limit)
        filter.cur_rep <- MSnbase::clean(filter.cur_rep, all=TRUE)
      
        file.remove(paste0(output.folder, spc.filename))
        
        try(MSnbase::writeMSData(object = as(filter.cur_rep, "MSnExp"), verbose = TRUE,
                               copy = TRUE,
                               file = paste0(output.folder, spc.filename) ),silent=FALSE)
        status.files <- rbind(status.files, c(samples.info$sample[file],
                                              spc.filename))
        write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
        ':   Replicate: ',spc.filename, " saved."),file=log.file,append=TRUE)
              
      }
    }
}

if ( nrow(status.files) > 0 ){
  colnames(status.files) <- c("sample", "replicate.file")
  n.error.files <- nrow(status.files[status.files$replicate.file %in% "error",])
}else{
  script.error <- TRUE
}


    if (debug_app==TRUE){
      save(data.folder,
         samples.info,
         status.files,
         n.error.files,
         log.file,
         file=paste0(data.folder, "variables_step_2.Rda") 
     )
    }


#if (script.error == TRUE | nrow(status.files) == 0 ){
if ( script.error == TRUE | n.error.files == nrow(status.files) ) {
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
           ':*** None of the files can be processed *** '),file=log.file,append=TRUE)
  cat('\n\n## Error: None of the files can be processed', '\n\n')
  knitr::knit_exit()
}else{
  
  status.files <- status.files[ !(status.files$replicate.file %in% "error"), ]
  
  merged.status.files <- merge(status.files, samples.info, by="sample", all.x = TRUE)
  rownames(merged.status.files) <- merged.status.files$replicate.file 
  
  samples.info <- samples.info[ samples.info$sample %in% unique(merged.status.files$sample) , ]
  
}


```



```{r, echo=FALSE,warning=FALSE,message=FALSE,fig.pos='H',fig.align='center',out.width='100%',fig.height=5,fig.width=9, results='asis'}

#################
################# Process - step 2
#################

set.seed(12345)

    
  if (debug_app==TRUE){
        save(data.folder,
             samples.info,
             status.files,
             merged.status.files,
             file=paste0(data.folder, "variables_step_2.Rda") 
         )
    }
    
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
': --------------------------------------------------'),file=log.file,append=TRUE)
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
': Second step'),file=log.file,append=TRUE)

BiocParallel::register(BiocParallel::SerialParam())
processed.sps <- Spectra::Spectra(paste0(output.folder,merged.status.files$replicate.file), backend = Spectra::MsBackendMzR())

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
      ': Binning'),file=log.file,append=TRUE)
processed.sps.bin <- Spectra::bin(processed.sps, binSize = input.binSize)
invisible(gc())

################
################  --- extracting mz and int
################

sps.mzs <- list()
for (i in 1:length(processed.sps.bin)){
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Extracting mz: ', i, " of ", length(processed.sps.bin)),file=log.file,append=TRUE)
  sps.mzs[[i]] <- data.frame(mz = Spectra::mz(processed.sps.bin[i])[[1]], 
                             intensity = Spectra::intensity(processed.sps.bin[i])[[1]] ) |> 
                  subset(intensity!=0) |> getElement("mz")
  invisible(gc())
  
}
unique.sps.mzs <- unique(Reduce(c,sps.mzs))
sps.bin.df <- setNames(data.frame(matrix(ncol = length(unique.sps.mzs), nrow = length(processed.sps.bin))), c(unique.sps.mzs))
for (i in 1:length(processed.sps.bin) ){
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Extracting intensity: ', i, " of ", length(processed.sps.bin)),file=log.file,append=TRUE)
  temp.df <- data.frame(mz = Spectra::mz(processed.sps.bin[i])[[1]], 
                             intensity = Spectra::intensity(processed.sps.bin[i])[[1]] ) |> 
              subset(intensity!=0)
  message("item ", i, ":  ", length(temp.df$intensity), " intensities - and mzs: ", length(as.character(temp.df$mz)))

  sps.bin.df[i,as.character(temp.df$mz)] <- temp.df$intensity
  
  vec.na.mz <- which(is.na(sps.bin.df[i,]))
  na.mz.names <- colnames(sps.bin.df)[vec.na.mz]
  
  #sps.bin.df[i,] <- sps.bin.df[i,]  %>%  mutate(across(where(is.numeric), ~replace(., is.na(.), 0)))
  sps.bin.df[i, na.mz.names] <- 0

  invisible(gc())
}
row.names(sps.bin.df) <- basename(processed.sps.bin$dataOrigin)

    if (debug_app==TRUE){
      save(sps.bin.df, file=paste0(data.folder,"sps.bin.df.Rda"))
    }

################
################  --- end of extracting mz and int
################

##############################
################# parallel ##
if(.Platform$OS.type=="windows"){ # If we are on windows
  # Snow-like functionality
  cl<- parallel::makeCluster(n.cores) # adjust according to the number of available cores (CPU)
  doParallel::registerDoParallel(cl)
}else{ # If we are on unix
  # Multi Core functionality
  doParallel::registerDoParallel(cores = n.cores)
}
#################parallel
###############################


write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Removing null columns...' ),file=log.file,append=TRUE)

sps.bin.df <- sps.bin.df[, colSums(sps.bin.df != 0, na.rm = TRUE) > 0] 

if (input.binSize>=1){
  colnames(sps.bin.df) <- trunc(as.numeric( colnames(sps.bin.df) ))
}
invisible(gc())
if (ncol(sps.bin.df) >= 2){

  if (input.make.heatmaps == "TRUE"){
    cat('\n\n## Hierarchical clustering heatmap (raw data) \n') 
    cat('\n\n Hierarchical clustering heatmap of the samples (in rows) and m/z values (columns) of the dataset after scan selection and data alignment. The color represents m/z intensity values. \n\n') 
    
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
    ': Creating heatmap: ', ncol(sps.bin.df), " number of columns" ),file=log.file,append=TRUE)
    heatmap(as.matrix(sps.bin.df))

  }
}


write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
': Binning: OK'),file=log.file,append=TRUE)

sps.bin.df <- sps.bin.df %>% dplyr::relocate(order(as.numeric(names(.))))

processed.sps.bin.df <- sps.bin.df
rownames(processed.sps.bin.df) <-  basename(processed.sps$dataOrigin)
#all.equal(basename(processed.sps$dataOrigin) , merged.status.files$replicate.file )

df.export <- data.frame(samples = rownames(processed.sps.bin.df), 
                        class = as.character(merged.status.files[rownames(processed.sps.bin.df),"class"]), 
                        processed.sps.bin.df)
colnames(df.export)[3:ncol(df.export)] <- (as.numeric(colnames(processed.sps.bin.df)))

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Exporting processed data '),file=log.file,append=TRUE)
write.table(x = df.export,file = paste0(data.folder, "Data","_metaboanalyst.csv"), sep=",", row.names=FALSE, quote = F)

    if (debug_app==TRUE){
      save(df.export, file=paste0(data.folder,"df.export.Rda"))
    }

cat('\n\n File exported to: ', paste0(data.folder, "Data","_metaboanalyst.csv") ,'  \n\n') 


names(cores)[1:length(unique(df.export$class))] <- unique(df.export$class)

#---------- pca
cat('\n\n## PCA (raw data) \n\n') 
cat('\n\n  PCA of the dataset after scan selection and alignment. All inputed classes were included in the analysis. Note that the PCA analysis was performed for data visualization purposes only, no normalization algorithm was executed prior to the analysis.  \n\n') 

pca <- prcomp(df.export[,3:ncol(df.export)], scale = TRUE)
scores <- as.data.frame(pca$x)
scores$class <- df.export$class

pca.pecents <- pca$sdev^2/sum(pca$sdev^2)*100
pca.pecents.df <- data.frame(PC = paste0("PC", 1:length(pca.pecents)), Porcentagem = pca.pecents)

plot.pca <- ggplot2::ggplot(scores, aes(x = PC1, y = PC2, color = class)) +
  ggplot2::geom_point(size = 3) +
  scale_color_manual(values = cores ) +
  ggplot2::xlab(paste0("PC1 (", round(pca.pecents[1], 1), "%)")) +
  ggplot2::ylab(paste0("PC2 (", round(pca.pecents[2], 1), "%)")) +
  #ggplot2::labs(title = "PCA")+ 
  ggplot2::theme_bw()
print(plot.pca)

#----------- end of pca

#----------- mean of data

df.export.mean <- df.export %>% 
                  dplyr::group_by(class) %>%
                  dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean))
invisible(gc())

#----------- end of mean of data

################
################  --- plot mean spectra
################
#---------- processed mean spectra


df.export.class.mean <- S4Vectors::DataFrame(
    msLevel = c(rep(1L,nrow(df.export.mean))),
    polarity = c(rep(1L,nrow(df.export.mean))),
    id = df.export.mean$class,
    name = df.export.mean$class)

## Assign m/z and intensity values.
df.export.class.mean$mz <- rep(list(as.numeric(colnames(df.export.mean[,3:ncol(df.export.mean)]))), nrow(df.export.mean))
df.export.class.mean$intensity <- lapply(as.data.frame(t(df.export.mean[,3:ncol(df.export.mean)])), unlist)

obj.df.export.class.mean <- Spectra::Spectra(df.export.class.mean)

########### end processed spectra -----

cat('\n\n## Spectra plot (raw data)  \n\n') 

Spectra::plotSpectraOverlay(obj.df.export.class.mean, lwd = 2, col = cores[unique(df.export.mean$class)],
                            main="Overlaid mean mass spectra")
legend("topright", col = cores[unique(df.export.mean$class)], legend = obj.df.export.class.mean$name, pch = 15)

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Plotting mean spectra per class'),file=log.file,append=TRUE)
for (m in 1:nrow(df.export.mean)){
  Spectra::plotSpectra(obj.df.export.class.mean[m], lwd = 2, col = cores[obj.df.export.class.mean$name[m]],
                              main=obj.df.export.class.mean$name[m] )
  legend("topright", col = cores[obj.df.export.class.mean$name[m]], legend = obj.df.export.class.mean$name[m], pch = 15)
}

################
################  --- end if processed mean spectra
################


################
################  --- replicate filter
################

n.total.features.replicate.filter <- 0
n.total.features.replicate <- 0
if (input.replicate.filter == "TRUE"){
  
cat('\n\n## Analyze replicates  \n\n')
cat('#### Process to evaluate features of replicates.','\n\n')
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Analyze replicates. Limit = ',input.value.replicate.filter, "%"  ),file=log.file,append=TRUE)


df.export.with.replicates <- df.export %>%
        dplyr::mutate(replicate = as.character(merged.status.files[rownames(df.export),"replicate"])) %>% 
        dplyr::relocate(replicate)


####### datamatrix before procedure

plotDat <- tidyr::gather(df.export.with.replicates, key = "replicate2", value = "value", -c(replicate,class,samples))
plotDat$value[plotDat$value > 0] <- 1

plot.before.rem.feat <- ggplot2::ggplot(plotDat, aes(replicate, replicate2, col = value, fill = value)) +
  ggplot2::geom_tile() +
  ggplot2::scale_fill_gradient2(low = "#F5B7B1", mid= "#F5B7B1", high = "#85C1E9") +
  ggplot2::scale_color_gradient2(low = "#F5B7B1", mid="#F5B7B1",  high = "#85C1E9") +
  ggplot2::theme(axis.ticks.x = ggplot2::element_blank(),
        axis.text.x = ggplot2::element_blank(),
        axis.title.x = ggplot2::element_text(size=10, face="bold"),
        axis.text.y = ggplot2::element_text(size=10, face="bold"),
        axis.title.y = ggplot2::element_text(size=10, face="bold"),
        legend.position = "None")+
  ggplot2::labs(y = "m/z", x = "Class replicate")+
  ggplot2::facet_wrap(~class, scales = 'free_y', ncol = 1)  + ggplot2::coord_flip()

#######
rm(plotDat)

n.total.features.replicate <- ncol(df.export)-2
#input.value.replicate.filter <- 80


invisible(gc())
#df.export.with.replicates <- df.export.with.replicates[,1:10000]
#df.export.with.replicates$replicate %in% "blank"
#df.export.with.replicates[df.export.with.replicates$replicate %in% "blank",4:ncol(df.export.with.replicates)] <- 100

rm(df.export)

percent.bins <- seq(1,100,10) / 100

holder <- foreach::foreach(x=4:ncol(df.export.with.replicates), 
                  .combine = "cbind", .packages='dplyr') %dopar% {
  #print(x)
  cur.item.col <- df.export.with.replicates %>% dplyr::select(c(1,3), x )
  cur.item.col <- cur.item.col[rownames(df.export.with.replicates),]

  if ( x %in% floor((percent.bins * ncol(df.export.with.replicates)) )   ){
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
      ':  status -  ', formatC( (x / ncol(df.export.with.replicates))*100, digits=2,format="f") , "%"),
      file=log.file,append=TRUE)
  }


  replicate.filter.features <- cur.item.col %>%
        dplyr::group_by(class,replicate) %>%
        dplyr::summarise(dplyr::across(dplyr::where(is.numeric), ~sum(. > 0)/sum(!is.na(.)) )) %>% 
        as.data.frame()
  
  not.pass.replicates <- replicate.filter.features[ replicate.filter.features[,3] < (input.value.replicate.filter/100),c(1,2)]
  
  cur.item.col[ (cur.item.col$replicate %in% not.pass.replicates$replicate) & 
                (cur.item.col$class %in% not.pass.replicates$class) , 3] <- 0
  cur.item.col <- cur.item.col[rownames(df.export.with.replicates),]

  return( subset(cur.item.col, select = 3) )
}



    if (debug_app==TRUE){
      save(holder, file=paste0(data.folder, "holder.replicate.Rda") )
    }


      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
      ':  status -  ', formatC( 100, digits=2,format="f") , "%"),
      file=log.file,append=TRUE)
      
holder <- holder[rownames(df.export.with.replicates),]
holder <- holder[, colSums(holder != 0, na.rm = TRUE) > 0] 

n.total.features.replicate.filter <- ncol(holder)

df.export <- cbind(subset(df.export.with.replicates, select = c(samples,class) ),
                   holder)

df.export.with.replicates.class.rep.mean <- cbind(subset(df.export.with.replicates, select = c(replicate,class) ), holder) %>%
        dplyr::group_by(class, replicate) %>%
        dplyr::summarise(dplyr::across(dplyr::where(is.numeric), ~base::mean(.) ) ) %>%
        as.data.frame()
# 
# library(ggplot2)
# library(dplyr)
# library(tidyr)

plotDat <- tidyr::gather(df.export.with.replicates.class.rep.mean, key = "replicate2", value = "value", -c(replicate,class))
plotDat$value[plotDat$value > 0] <- 1

plot.rem.feat <- ggplot2::ggplot(plotDat, aes(replicate, replicate2, col = value, fill = value)) +
  ggplot2::geom_tile() +
  ggplot2::scale_fill_gradient2(low = "#F5B7B1", mid= "#F5B7B1", high = "#85C1E9") +
  ggplot2::scale_color_gradient2(low = "#F5B7B1", mid="#F5B7B1",  high = "#85C1E9") +
  ggplot2::theme(axis.ticks.x = ggplot2::element_blank(),
        axis.text.x = ggplot2::element_blank(),
        axis.title.x = ggplot2::element_text(size=10, face="bold"),
        axis.text.y = ggplot2::element_text(size=10, face="bold"),
        axis.title.y = ggplot2::element_text(size=10, face="bold"),
        legend.position = "None")+
  ggplot2::labs(y = "m/z", x = "Class replicate")+
  ggplot2::facet_wrap(~class, scales = 'free_y', ncol = 1)  + ggplot2::coord_flip()


} #end of replicate filter

```


```{r, results = 'asis'}
cat('\n\n## {.tabset}  \n\n')
```


```{r, echo=FALSE, results='asis', warning=FALSE,message=FALSE,fig.pos='H',fig.align='center',out.width='100%',fig.height=5,fig.width=9}


if ( (n.total.features.replicate.filter <  n.total.features.replicate) && (input.replicate.filter == "TRUE")) {
  #cat('\n\n### Total of removed features = ', n.total.features.replicate - n.total.features.replicate.filter  ,'  \n\n') 
  cat('\n\n Procedure for removing features from replicas (specified in samples_info) that show variation greater than',(input.value.replicate.filter),'%.
The figure below illustrates the removal through the colors lightbrown (ion removal) and turquoise blue (ion permanence) ' , '\n')

  cat('\n\n### Dataset after procedure', '\n')
     print(plot.rem.feat)
  cat('\n')
  cat('\n\n### Dataset before procedure','\n')
    print(plot.before.rem.feat)
  cat('\n')
  cat( '\n\n## {-}', '\n\n')

  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Exporting filtered replicates '),file=log.file,append=TRUE)
  write.table(x = df.export,
              file = paste0(data.folder,"Data","_metaboanalyst_replicates_filtered_",input.value.replicate.filter,".csv"),
              sep=",", row.names=FALSE, quote = F)
  cat('\n\n File exported to: ', paste0(data.folder,"Data","_metaboanalyst_replicates_filtered_",input.value.replicate.filter,".csv") ,'  \n\n')

  
}else{
  cat('\n\n### No features have been removed.  \n\n') 
}

################
################  --- end of replicate filter
################


```


```{r, echo=FALSE,warning=FALSE,message=FALSE,fig.pos='H',fig.align='center',out.width='100%',fig.height=5,fig.width=9, results='asis'}


#df.export[,3:ncol(df.export)] <- df.export[,3:ncol(df.export)] / 100000
#load("~/r_develop/TENGI/df.export.Rda")

df.export.mean <- df.export %>% 
                  dplyr::group_by(class) %>%
                  dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean))
invisible(gc())

######################################################
# filtrar os picos do branco:
# Remover os ions do branco que tenham uma intensidade > 1/3  nas amostras

################
################  --- blank remove
################

if (input.subtract.group != ""){
  
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Subtracting ', input.subtract.group, ' ions' ),file=log.file,append=TRUE)

cat('\n\n## Subtraction procedure \n\n') 
cat('#### Subtraction of the ', input.subtract.group ,' ions present in the dataset.', 
    'The procedure analyzes the intensity ratio of the samples divided by ',input.subtract.group,'group. If the ratio is less than ', input.min.fold ,' (minimum fold change), the ion is removed. ','\n\n')

#write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Removing the ions from ', input.subtract.group ),file=log.file,append=TRUE)
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Minimum fold change: ', input.min.fold ),file=log.file,append=TRUE)

vector.blank.mean <- as.numeric(subset(df.export.mean,class==input.subtract.group, select = -c(class)) )
df.blank.remove <- data.frame()
n.total.features.replicate <- ncol(df.export)-2

df.export.info <- df.export %>%
        dplyr::mutate(replicate = as.character(merged.status.files[rownames(df.export),"replicate"]) ) %>% 
        dplyr::relocate(replicate) %>% dplyr::select(samples,class, replicate)

df.export.replicate.mean <- df.export %>%
        dplyr::mutate(replicate = as.character(merged.status.files[rownames(df.export),"replicate"]) ) %>% 
        dplyr::relocate(replicate) %>% 
        dplyr::filter(class!=input.subtract.group) %>% 
        dplyr::group_by(replicate) %>%
        dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean))

compare.blank.mean <- df.export.replicate.mean[,2:ncol(df.export.replicate.mean)] %>%
                      plyr::adply(.,1, function(u) ( ( u  /  vector.blank.mean ) < input.min.fold ) )
df.features <- colnames(compare.blank.mean)

for(i in 1:nrow(df.export.replicate.mean)){
  blank.ions <- integer()
  i.replicate <- df.export.replicate.mean$replicate[i]
  blank.ions <-  which( compare.blank.mean[i,] == TRUE  )
   
  if ( length(blank.ions) > 0) {
    
    df.export[df.export$samples %in% df.export.info[df.export.info$replicate==i.replicate, "samples"], df.features[blank.ions] ] <- 0
    
    df.blank.remove <- rbind(df.blank.remove,
                             c(i.replicate,
                               length(blank.ions),
                               formatC((length(blank.ions) / n.total.features.replicate)*100,
                                       digits=2,format="f")) )
    
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
    ':    -  Removing ', length(blank.ions), " ions from replicate ", i.replicate),file=log.file,append=TRUE)
  }

}


data_filtered <- df.export %>% dplyr::filter(class!=input.subtract.group)

write.table(x = data_filtered,
              file = paste0(data.folder, "Data_substracted_", input.min.fold ,"_MFC_metaboanalyst.csv"), sep=",", row.names=FALSE, quote = F)

cat('\n\n File exported to: ', paste0(data.folder, "Data_substracted_", input.min.fold ,"_MFC_metaboanalyst.csv") ,'  \n\n') 

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Subtraction procedure: OK ' ),file=log.file,append=TRUE)

  if (nrow(df.blank.remove) > 0){
    colnames(df.blank.remove) <- c("Replicate", "Features removed", "Removal percentage (%)")
    print_paged_df(df.blank.remove)
  }else{
    cat('\n\n### No features have been removed.  \n\n') 
  }

df.export <- data_filtered
df.export[is.na(df.export)] <- 0

}

################
################  --- end of blank remove
################


#clean zero cols from data -----------------------
df.export <- df.export[, colSums(df.export != 0, na.rm = TRUE) > 0] 
#-------------------------------------------------

################
################  --- Class filter
################

n.total.classes <- length(unique(df.export$class))

if (input.sample.filter != "no.sample.filter" & (n.total.classes > 0) ){

  cat('\n\n## Filter samples  \n\n') 
#cat('#### Filtering ions by class consists of removing ions, within each class, that are not present in at least ',input.class.mean.filter,'% of the samples #of the respective class.','\n\n')
 
  df.export.bkp <- df.export
  
if (input.sample.filter == "sample.filter.by.class"){
  cat('\n\n## Filter with-in class  \n\n') 
  
  cat('#### Procedure to filter ions by class, remove ions from each class that are present in less than ',input.class.mean.filter,'% of the samples within that class.', '\n\n')
 
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Filtering ions by class. Limit = ', input.class.mean.filter,"%" ),file=log.file,append=TRUE)
  


if (QC_app==FALSE){
   write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Remove QC class from samples filter '),file=log.file,append=TRUE)
  df.export.QC <- df.export %>% filter(toupper(class)=="QC")
  df.export <- df.export %>% filter(toupper(class)!="QC")
}


class.filter.features <- df.export %>%
        dplyr::mutate(replicate = as.character(merged.status.files[rownames(df.export),"replicate"]) ) %>% 
        dplyr::relocate(replicate) %>% 
        dplyr::group_by(class, replicate) %>%
        dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean)) %>% 
        dplyr::select(-replicate) %>% 
        dplyr::group_by(class) %>%
        dplyr::summarise(dplyr::across(dplyr::where(is.numeric), ~sum(. > 0)/sum(!is.na(.)) )) 

invisible(gc())
df.class.result <- data.frame()
n.total.features.class <- ncol(df.export)-2

class.holder <- foreach::foreach(x=1:length(class.filter.features$class),
                           .combine = "c", .packages='dplyr') %dopar% {
                             
                      item.class <- class.filter.features$class[x]
                      
                      class.exclude.features <- class.filter.features %>%
                        dplyr::filter(class == item.class) %>%
                        dplyr::select_if(~ . < (input.class.mean.filter/100)) %>% colnames()
                      
                      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
                      ':    -  Removing ', length(class.exclude.features), " features from ", item.class),file=log.file,append=TRUE)
                      
                      list(c(item.class, class.exclude.features))
                  }

invisible(gc())

for(list.item in class.holder){
  if (length(list.item) == 1){
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
                 ':    -  0 features to remove from ', list.item[1]),file=log.file,append=TRUE)
  }else{
    item.class <- list.item[1]
    class.exclude.features <- list.item[2:length(list.item)]
    df.export[df.export$class==item.class, class.exclude.features] <- 0
    df.class.result <- rbind(df.class.result,
                             c(item.class,
                              length(class.exclude.features),
                              formatC( ( length(class.exclude.features) / n.total.features.class)*100,
                                      digits=2,format="f")) )

  }
}

invisible(gc())
#clean zero cols from data -----------------------
df.export <- df.export[, colSums(df.export != 0, na.rm = TRUE) > 0] 
#-------------------------------------------------

if ( nrow(df.class.result) > 0){
  colnames(df.class.result) <- c("Class", "Features removed", "Removal percentage (%)")
  print_paged_df(df.class.result) 
}else{
  cat('\n\n### No features have been removed.  \n\n') 
  df.export<-df.export.bkp
}


if (ncol(df.export)==2){
  
  cat('\n\n### Filter with-in class: No feature has been selected. 
               This occurs for very high percentage values  \n\n') 
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Filter with-in class: No feature has been selected. 
               This occurs for very high percentage values'),file=log.file,append=TRUE)
  
  df.export <- df.export.bkp
  
}else{

  
  if (QC_app==FALSE){
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
    ': Append QC to processed data '),file=log.file,append=TRUE)
    
    if (debug_app == TRUE){
      save(df.export,
           df.export.QC,
           df.export.bkp,
           df.class.result,
           file=paste0(data.folder, "qc.datasets.Rda") 
       ) 
    }
    
    #df.export <- rbind(df.export, df.export.QC )
    df.export <- dplyr::bind_rows(df.export.QC , df.export )
    
    order.names.mz <- data.frame(ID = seq(1,ncol(df.export)-2,1) , features = colnames(df.export)[3:ncol(df.export)],
                                 mz = as.numeric(colnames(df.export)[3:ncol(df.export)]))
    order.names.mz <- order.names.mz %>% dplyr::arrange((mz))
    
    df.export <- df.export[,c("samples", "class", order.names.mz$features )]
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Working on QC data...'),file=log.file,append=TRUE)
    df.export <- df.export %>%  dplyr::mutate(dplyr::across(dplyr::where(is.numeric), ~replace(., is.na(.), 0)))
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': QC OK.'),file=log.file,append=TRUE)

  }
  
  
  ncol.before <- ncol(df.export) -2
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Removing null columns. Total = ', ncol.before ),file=log.file,append=TRUE)
  
  df.export <- df.export[, colSums(df.export != 0, na.rm = TRUE) > 0] 
  
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Total removed = ', ncol.before - ncol(df.export) ),file=log.file,append=TRUE)
  
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Exporting filtered data per class'),file=log.file,append=TRUE)
  write.table(x = df.export,
              file = paste0(data.folder,"Data","_metaboanalyst_class_filtered_",input.class.mean.filter,".csv"), 
              sep=",", row.names=FALSE, quote = F)
  cat('\n\n File exported to: ', paste0(data.folder,"Data","_metaboanalyst_class_filtered_",input.class.mean.filter,".csv") ,'  \n\n') 

}
  # end of if sample.filter.by.class 

#############################################################
#############################################################
#############################################################
#############################################################
#############################################################
#############################################################


}else{
  #"Filter all samples" = "sample.filter.all.samples"
  
    cat('\n\n## Filter all samples  \n\n') 
  
  cat('#### Procedure to filter ions from all samples, remove ions from samples that are present in less than ',input.class.mean.filter,'% of the dataset.', '\n\n')
 
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Filtering ions by the limit = ', input.class.mean.filter,"%" ),file=log.file,append=TRUE)
  
df.export.bkp <- df.export

samples.filter.features <- df.export %>%
        dplyr::mutate(replicate = as.character(merged.status.files[rownames(df.export),"replicate"]) ) %>% 
        dplyr::mutate(sample = as.character(merged.status.files[rownames(df.export),"sample"]) ) %>% 
        dplyr::relocate(replicate,sample) %>% 
        dplyr::group_by(sample) %>%
        dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean)) %>% 
        dplyr::group_by(sample) %>%
        dplyr::summarise(dplyr::across(dplyr::where(is.numeric), ~sum(. > 0)/sum(!is.na(.)) )) 

samples.filter.features.colsum <-  data.frame(Feature = colSums(samples.filter.features != 0, na.rm = TRUE))
samples.filter.features.colsum$percent <- samples.filter.features.colsum$Feature / nrow(samples.filter.features)
samples.filter.features.filtered <- samples.filter.features.colsum %>% filter(percent >= (input.class.mean.filter/100) )
samples.filter.features.filtered.selected <- rownames(samples.filter.features.filtered)[2:nrow(samples.filter.features.filtered)]

invisible(gc())

df.export <- df.export[,c("samples", "class",samples.filter.features.filtered.selected)]


if (ncol(df.export)==2){

  cat('\n\n### Filter samples: No feature has been selected.
               This occurs for very high percentage values  \n\n')
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Filter samples: No feature has been selected.
               This occurs for very high percentage values'),file=log.file,append=TRUE)

  df.export <- df.export.bkp

}else{

  ncol.before <- ncol(df.export)-2
  # write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  # ': Removing null columns. Total = ', ncol.before ),file=log.file,append=TRUE)

  df.export <- df.export[, colSums(df.export != 0, na.rm = TRUE) > 0]

  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
  ': Total of removed features = ', (ncol(df.export.bkp)-2) - (ncol(df.export)-2) ),file=log.file,append=TRUE)

  cat('\n\n### Total of removed features = ',(ncol(df.export.bkp)-2) - (ncol(df.export)-2) , '  \n\n') 
  
  write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Exporting filtered data (samples)'),file=log.file,append=TRUE)
  write.table(x = df.export,
              file = paste0(data.folder,"Data","_metaboanalyst_samples_filtered_",input.class.mean.filter,".csv"),
              sep=",", row.names=FALSE, quote = F)
  cat('\n\n File exported to: ', paste0(data.folder,"Data","_metaboanalyst_samples_filtered_",input.class.mean.filter,".csv") ,'  \n\n')

}

  
} 
  

  
} #end of samples filter

  rm(df.export.bkp)

################
################  --- end of Class filter
################

```


```{r, echo=FALSE,warning=FALSE,message=FALSE,fig.pos='H',fig.align='center',out.width='100%',fig.height=5,fig.width=9, results='asis'}




if ( n.total.classes > 0 ){

  if (ncol(df.export) > 3){
    #class.filtered.hm <- class.filtered.df[,3:ncol(class.filtered.df)]
    class.filtered.hm <- subset(df.export, select = -c(samples, class))
    class.filtered.hm[is.na(class.filtered.hm)] <- 0
    #zeros <- colSums(class.filtered.hm) == 0
    #class.filtered.hm <- subset(class.filtered.hm, select = !c(zeros))
    
    if (input.make.heatmaps == "TRUE"){
      ##cat('\n\n## Heatmap (class filtered) \n\n') 
      cat('\n\n## Hierarchical clustering heatmap (processed) \n') 
      cat('\n\n Hierarchical clustering heatmap of the samples (in rows) and m/z values (columns) of the dataset after processing. The color represents m/z intensity values.  \n\n') 
      write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),
        ': Creating heatmap: ', ncol(class.filtered.hm), " number of columns" ),file=log.file,append=TRUE)
      heatmap(as.matrix(class.filtered.hm), labRow=df.export$class)
    }

    #---------- pca
    cat('\n\n## PCA (processed) \n\n') 
    cat('\n\n  PCA of the dataset after processing. Note that the PCA analysis was performed for data visualization purposes only, no normalization algorithm was executed prior to the analysis. \n\n') 
    
    pca <- prcomp(class.filtered.hm, scale = TRUE)
    scores <- as.data.frame(pca$x)
    scores$class <- df.export$class
    
    pca.pecents <- pca$sdev^2/sum(pca$sdev^2)*100
    pca.pecents.df <- data.frame(PC = paste0("PC", 1:length(pca.pecents)), Porcentagem = pca.pecents)
    
    plot.pca <- ggplot2::ggplot(scores, aes(x = PC1, y = PC2, color = class)) +
    ggplot2::geom_point(size = 3) +
    scale_color_manual(values = cores ) +
    ggplot2::xlab(paste0("PC1 (", round(pca.pecents[1], 1), "%)")) +
    ggplot2::ylab(paste0("PC2 (", round(pca.pecents[2], 1), "%)")) +
    #ggplot2::labs(title = "PCA after filter with-in class")+ 
    ggplot2::theme_bw()
    print(plot.pca)
    #----------- end of pca

    df.export.mean <- df.export %>% 
                      dplyr::group_by(class) %>%
                      dplyr::summarise(dplyr::across(tidyselect::where(is.numeric),base::mean))
    invisible(gc())
    
    ################
    ################  --- plot mean spectra - after processing
    ################
    
    df.export.class.mean <- S4Vectors::DataFrame(
        msLevel = c(rep(1L,nrow(df.export.mean))),
        polarity = c(rep(1L,nrow(df.export.mean))),
        id = df.export.mean$class,
        name = df.export.mean$class)
    
    ## Assign m/z and intensity values.
    df.export.class.mean$mz <- rep(list(as.numeric(colnames(df.export.mean[,3:ncol(df.export.mean)]))), nrow(df.export.mean))
    df.export.class.mean$intensity <- lapply(as.data.frame(t(df.export.mean[,3:ncol(df.export.mean)])), unlist)
    obj.df.export.class.mean <- Spectra::Spectra(df.export.class.mean)
    
    ########### end processed spectra -----
    cat('\n\n## Spectra plot (processed data)  \n\n') 
    
    Spectra::plotSpectraOverlay(obj.df.export.class.mean, lwd = 2, col = cores[unique(df.export.mean$class)],
                                main="Overlaid mean mass spectra")
    legend("topright", col = cores[unique(df.export.mean$class)], legend = obj.df.export.class.mean$name, pch = 15)
    
    write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Plotting mean spectra per class'),file=log.file,append=TRUE)
    for (m in 1:nrow(df.export.mean)){ 
      Spectra::plotSpectra(obj.df.export.class.mean[m], lwd = 2, col = cores[obj.df.export.class.mean$name[m]],
                                  main=obj.df.export.class.mean$name[m] )
      legend("topright", col = cores[obj.df.export.class.mean$name[m]], legend = obj.df.export.class.mean$name[m], pch = 15)
      
      write.table( data.frame(mz = colnames(df.export.mean)[-1] , 
                              int = as.numeric(df.export.mean[m,2:ncol(df.export.mean)])),
                   file=paste0(output.folder, "mean_" ,as.character(df.export.mean[m,1]), ".csv"),  sep=";")
      
    }
    
    ################
    ################  --- end if processed mean spectra
    ################
        
        
  
  }

  #din <- data.table::fread(file="C:/Users/Planck/Documents/MTBLS117/Data_metaboanalyst_class_filtered_80.csv", header = T)

}

```


```{r, echo=FALSE,warning=FALSE,message=FALSE,fig.pos='H',fig.align='center',out.width='100%',fig.height=5,fig.width=9, results='asis'}

write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': END' ),file=log.file,append=TRUE)
write(paste0(format(Sys.time(), "%Y-%m-%d_%H-%M-%S"),': Session parameters:' ),file=log.file,append=TRUE)
write.table(format(session.parameters),file=log.file, append = TRUE, col.names = F)

#Stop cluster
parallel::stopCluster(cl)

```







